{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8acaf1c3-a604-4009-8176-09a91a047c41",
   "metadata": {},
   "source": [
    "# Make thickness histograms\n",
    "for AH Manuscript 2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "59b43ac8-f0fa-472d-a323-e1cd53b14539",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "from copy import deepcopy\n",
    "from scipy import interpolate\n",
    "from shapely.geometry import Polygon, MultiPolygon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9dd1909e-2ff6-42e1-aaa3-9bd96bd29e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "## import cropping data for the packages.\n",
    "filenm = 'agubh2-500mint'+'.xlsx'\n",
    "mypath = f'/Volumes/SAF_Data/NAYS2DH_files/Data/BarCSVs/concat-files/{filenm}'\n",
    "allbars = pd.read_excel(mypath, header=0, usecols = 'A:J') ## change if you add more columns to the raw dataset\n",
    "\n",
    "##create a numpy array of the start, end, left and right indices of the array\n",
    "indices = pd.concat(allbars['iloc'], [allbars['StartTime'], allbars['EndTime'], allbars['LeftEdge'], allbars['RightEdge']], axis = 1).to_numpy(dtype = float)\n",
    "\n",
    "\n",
    "### locate arrays\n",
    "arrayfolder = 'agubh2_agu22'\n",
    "tpo_savefol = 'agubh2_agu22_tpo'\n",
    "init = f'/Volumes/SAF_Data/NAYS2DH_files/Data/nparrays/barpkg-arrays/{arrayfolder}'\n",
    "\n",
    "## import datamaster so you ca build the sections\n",
    "idf = '0hfld' #identifier/classifier about the flood setting\n",
    "intstring = '2hour' #time interval of output\n",
    "nickname = 'agubh2-10km' #model nickname, agubh2, gentle_wide etc\n",
    "floodname ='_0hrflood'\n",
    "eqt = 65\n",
    "\n",
    "datnam = f'{idf}-datamaster-{intstring}-ud.npy' #name of the data file to upload\n",
    "dataloc = f'data-{nickname}{floodname}' #where csv files are\n",
    "\n",
    "datamaster = np.load(f'/Volumes/SAF_Data/NAYS2DH_files/Data/ConvertedArrays/{dataloc}/{datnam}', allow_pickle = True)\n",
    "\n",
    "## build a library of sections to crop--check the array folder and get ilocs\n",
    "sectionlist = [int(i) for i in os.listdir(init)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "9b829ab2-7983-43bd-a460-3a255d84ba96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "150\n",
      "200\n",
      "250\n",
      "300\n",
      "350\n",
      "400\n",
      "450\n",
      "500\n",
      "550\n",
      "600\n",
      "650\n",
      "700\n",
      "750\n",
      "800\n",
      "850\n",
      "900\n"
     ]
    }
   ],
   "source": [
    "for i in sectionlist:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "415ce247-d089-42ca-a7fb-5a1fd2fa90d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "gridx = 1001\n",
    "gridy = 26\n",
    "\n",
    "datacond = 1\n",
    "if datacond == 1:\n",
    "    cells = gridy\n",
    "else:\n",
    "    cells = gridx\n",
    "length = 1001 #length of the domain in the x direction\n",
    "erostart = 5\n",
    "erostop = 5\n",
    "\n",
    "num_timesteps = datamaster.shape[2] ##### or 168 for 2 weeks# len(os.listdir(filepathcore))-1 ###when u want to stop plotting\n",
    "\n",
    "datamaster = datamaster[:, :, :num_timesteps]\n",
    "# position = np.arange(0, length, dtype = float)\n",
    "# coevelev = np.empty([num_timesteps])\n",
    "# interval_to_plot = 120/60 #we want to plot every ___  HOURS \n",
    "end_t = num_timesteps #len(np.arange(1, num_timesteps, skipstep)) #number of timesteps in data master array\n",
    "# fldstart = ((thot_SS+fldstart_s)/3600)/interval_to_plot ###flood starttime, s\n",
    "spacing = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12a09cec-95f7-4cb3-8faa-801845e131c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for iloc in sectionlist:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "b7e0bf88-147d-4465-9b44-8cf4ceb93a1b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cropped, final dataset shape:  (26, 11, 382)\n",
      "Left bank max position:  241.882453863\n",
      "Right bank max position:  -230.065536143\n",
      "Shape of stratigraphy matrix:,  (382, 475)\n"
     ]
    }
   ],
   "source": [
    "## now do all the shit to build the section\n",
    "###Crop and sort the data by jloc (removing ilocs that are not the desired section) so its in section order and not streamwise\n",
    "# iloc = 100\n",
    "#crop data\n",
    "remove_ilocs = np.where(datamaster[:, 0, :] != iloc)\n",
    "data = np.delete(datamaster, remove_ilocs[0], axis=0)\n",
    "print('Cropped, final dataset shape: ', data.shape)\n",
    "\n",
    "#sort in cross stream direction from rightbank to left bank\n",
    "#test = np.empty_like(datamaster)    \n",
    "for i in range (0, num_timesteps):\n",
    "    data[:, :, i] = data[:, :, i][np.argsort(data[:, :, i][:, 3])]\n",
    "    #print(i, data[:, 3, i])\n",
    "\n",
    "### Now fill in arrays for elevation, position, shear etc...\n",
    "\n",
    "###Make the arrays to store data\n",
    "stratigraphy = np.empty([end_t, cells]) ###will hold data for topography accounting for changes due to erosion\n",
    "#print(elevation.shape) #elevation = np.empty([n, end_t])\n",
    "\n",
    "# print('Shape of prelim arrays: ', stratigraphy.shape)\n",
    "\n",
    "#this matrix is to record unmodified stratigraphy in the same shape as the eroded strat\n",
    "stratigraphy_idx = stratigraphy.copy()\n",
    "#stratigraphy_idx[:] =  np.nan\n",
    "# #print(stratigraphy)\n",
    "\n",
    "# shearstresseroded = stratigraphy.copy() #will hold data for shear stress accounting for changes due to erosion\n",
    "# #shearstresseroded[:] = np.nan\n",
    "# #print('!!!', shearstresseroded.shape)\n",
    "\n",
    "# stratflowdepth =  stratigraphy.copy() #will hold data for flow depth accounting for changes due to erosion\n",
    "# #stratflowdepth[:] = np.nan\n",
    "\n",
    "# scaleflowdepth =  stratigraphy.copy() #will hold data for local flow depth scaled to max accounting for changes due to erosion\n",
    "# #scaleflowdepth[:] = np.nan\n",
    "\n",
    "# froudedata =  stratigraphy.copy() #will hold data for local flow depth scaled to max accounting for changes due to erosion\n",
    "# #froudedata[:] = np.nan\n",
    "\n",
    "# velocity =  stratigraphy.copy()\n",
    "runtime = len(stratigraphy)\n",
    "#print(runtime)\n",
    "xposition =  stratigraphy.copy()\n",
    "\n",
    "in_section = np.where(datamaster[:, 0, -1]==iloc)\n",
    "in_section = in_section[0]\n",
    "bankpos = datamaster[:, 3, :][in_section]\n",
    "#print(bankpos)\n",
    "rightbank = bankpos.min() ###negativee\n",
    "leftbank = bankpos.max() #positive\n",
    "print('Left bank max position: ', leftbank)\n",
    "print('Right bank max position: ', rightbank)\n",
    "\n",
    "xy_strat = np.empty([end_t, int(3+np.round((leftbank-rightbank)/spacing, 0))]) # will put stratigraphies here, in proper x pos\n",
    "print('Shape of stratigraphy matrix:, ', xy_strat.shape)\n",
    "xy_strat[:] = np.nan\n",
    "# ages = np.empty_like(xy_strat)\n",
    "\n",
    "# #### Import, and fill the arrays that will be used for the rest of the code\n",
    "# 1. Import data for shear stress, flow depth, velocity and froude\n",
    "# 2. Interpolate data to represent actual channel dimensions and not grid dimensions\n",
    "# 3. Fill and remove any remaining nans from the arrays\n",
    "\n",
    "##### Import the data\n",
    "for time in range (0, data.shape[2]): #TIME\n",
    "    #print(stratigraphy[time, :].shape)\n",
    "    stratigraphy[time, :] = data[:, 7, time] #elevation change, elevation in 5\n",
    "    # shearstresseroded[time, :] = data[:, 6, time] \n",
    "    # stratflowdepth[time, :] = data[:, 4, time]\n",
    "    # froudedata[time, :] = data[:, 9, time]\n",
    "    # velocity[time, :] = data[:, 10, time]\n",
    "\n",
    "    ypos = data[:, 3, time]-rightbank #coreect supid centreline indexing\n",
    "    #print(ypos)\n",
    "    xposition[time, :] = ypos\n",
    "\n",
    "stratigraphy_idx = stratigraphy.copy()\n",
    "\n",
    "###you need to change the y positions from centreline position to actual positional data\n",
    "#print(xposition.max(axis = 1))\n",
    "\n",
    "##### these arrays will house interpolated data\n",
    "# shear = xy_strat.copy()\n",
    "# froude = xy_strat.copy()\n",
    "# scaleflow = xy_strat.copy() #flow depth scaled to max per time\n",
    "# trueflow = xy_strat.copy() #unscaled flow depth\n",
    "# flowvel = xy_strat.copy() #flow velocity\n",
    "\n",
    "# print('True shape, m: ', shear.shape, froude.shape, scaleflow.shape, trueflow.shape, flowvel.shape)\n",
    "\n",
    "#put all data values in their correct x/index position\n",
    "for t in range (0, end_t):\n",
    "    #print(t)\n",
    "    for idx, x in zip(np.arange(0, stratigraphy.shape[1]), xposition[t, :]):\n",
    "        #print(x)\n",
    "        #print(idx, x)\n",
    "        x = int(np.floor(x)) #rounding down positions, making integers so can use as index\n",
    "        #print(x, idx)\n",
    "        xy_strat[t, x] = stratigraphy[t, idx]\n",
    "        # shear[t, x] = shearstresseroded[t, idx]\n",
    "        # froude[t, x] = froudedata[t, idx]\n",
    "        # trueflow[t, x] = stratflowdepth[t, idx]\n",
    "        # scaleflow[t, x] = scaleflowdepth[t, idx]\n",
    "        # flowvel[t, x] = velocity[t, idx]\n",
    "    #plt.plot(xy_strat[t, :], '.')\n",
    "\n",
    "xy_topo = np.empty_like(xy_strat)\n",
    "xy_topo[:] = np.nan\n",
    "for t in range (0, end_t):\n",
    "    #print(t)\n",
    "    length = int(np.floor(xposition[t, -1]-xposition[t, 0])) #length of the section at time, t\n",
    "    pos = np.linspace(0, length, length) #create a metre scale array with each x pos = location\n",
    "    #dataint = np.linspace(int(np.round(xposition[t, 0], 0)), int(np.round(xposition[t, -1], 0)), length, dtype=int) #range of locations to interpolate over?\n",
    "    dataint = np.arange(xposition[t, 0], np.round(xposition[t, -1], 0), dtype=int)\n",
    "    #print(t, pos.max(), length)\n",
    "    #print(len(dataint))\n",
    "    #print(pos)\n",
    "\n",
    "    stratnotnan = xy_strat[t, :][~np.isnan(xy_strat[t, :])] #pull out real values of strat\n",
    "    # shearnotnan = shear[t, :][~np.isnan(shear[t, :])] #pull out real values of shear\n",
    "    # froudenotnan = froude[t, :][~np.isnan(froude[t, :])] #pull out real values of froude\n",
    "    # truefnotnan = trueflow[t, :][~np.isnan(trueflow[t, :])] #pull out real values of true flow depth\n",
    "    #scalefnotnan = scaleflow[t, :][~np.isnan(scaleflow[t, :])] #pull out real values of scaled flow depth\n",
    "    # velnotnan = flowvel[t, :][~np.isnan(flowvel[t, :])] #pull out real values of strat\n",
    "    #print(shear[t, :][~np.isnan(shear[t, :])])\n",
    "    #print(shearnotnan[:].shape, froudenotnan[:].shape, truefnotnan[:].shape, velnotnan[:].shape)\n",
    "    #print(xposition[t, :])\n",
    "    #print(dataint)\n",
    "    fx = interpolate.interp1d(xposition[t, :], stratnotnan[:], kind = 'cubic', fill_value = 'extrapolate') #stratigraphy interpolation\n",
    "    #print(fx)\n",
    "#     fsh = interpolate.interp1d(xposition[t, :], shearnotnan[:], kind = 'cubic', fill_value = 'extrapolate') #shear stress interpolation\n",
    "#     ffr = interpolate.interp1d(xposition[t, :], froudenotnan[:], kind = 'cubic', fill_value = 'extrapolate') #froude number interpolation\n",
    "#     ftf = interpolate.interp1d(xposition[t, :], truefnotnan[:], kind = 'cubic', fill_value = 'extrapolate') #true flow depth interpolation\n",
    "#     #fsf = interpolate.interp1d(xposition[t, :], scalefnotnan[:], kind = 'cubic') #scaled flow depth interpolation\n",
    "#     ffv = interpolate.interp1d(xposition[t, :], velnotnan[:], kind = 'cubic', fill_value = 'extrapolate') #flow veloity interpolation\n",
    "\n",
    "#     #print(fx(dataint))\n",
    "\n",
    "    xy_topo[t, dataint] = fx(dataint) #reassign strat\n",
    "    #print(xy_topo[t, :])\n",
    "    # shear[t, dataint] = fsh(dataint) #reassign shear\n",
    "    # froude[t, dataint] = ffr(dataint) #reassign froude\n",
    "    # trueflow[t, dataint] = ftf(dataint) #reassign true fd\n",
    "    # #scaleflow[t, 0:length] = fsf(pos) #reassign scaled fd\n",
    "    # flowvel[t, dataint] = ffv(dataint) #reassign flow vel\n",
    "\n",
    "        #plt.plot(xy_topo[t, :])\n",
    "    #plt.ylim(-3, 3)\n",
    "stratcondition = np.zeros_like(xy_topo)\n",
    "stratcondition[:] = np.nan\n",
    "erosurf = np.empty([end_t, xy_topo.shape[1]])\n",
    "erosurf[:] = np.nan\n",
    "ages = np.empty_like(xy_strat)\n",
    "strat = deepcopy(xy_topo)\n",
    "# halfwidth=25\n",
    "\n",
    "# for time in range (0, end_t):    \n",
    "#     for space in range (0, xy_topo.shape[1]):\n",
    "#         preexisting_strata = xy_topo[:time, :] #this is our search array, where we will erode\n",
    "#         willerode = np.where(preexisting_strata[:, space] > xy_topo[time, space])\n",
    "#         xy_topo[willerode, space] = xy_topo[time, space]\n",
    "#         ages[willerode, space] = time\n",
    "    \n",
    "# for i in range (end_t-2, -1, -1):\n",
    "#     fillinx = np.where(np.isnan(xy_topo[i, :]))\n",
    "#     xy_topo[i, fillinx] = xy_topo[i+1, fillinx]\n",
    "#     stratcondition[i, fillinx] = 1\n",
    "#     fillinsh = np.where(np.isnan(shear[i, :]))\n",
    "#     shear[i, fillinsh] = shear[i+1, fillinsh]\n",
    "#     fillinfr = np.where(np.isnan(froude[i, :]))\n",
    "#     froude[i, fillinfr] = froude[i+1, fillinfr]\n",
    "#     fillintf = np.where(np.isnan(trueflow[i, :]))\n",
    "#     trueflow[i, fillintf] = trueflow[i+1, fillintf]\n",
    "#     fillinsf = np.where(np.isnan(scaleflow[i, :]))\n",
    "#     scaleflow[i, fillinsf] = scaleflow[i+1, fillinsf]\n",
    "#     fillinfv = np.where(np.isnan(flowvel[i, :]))\n",
    "#     flowvel[i, fillinfv] = flowvel[i+1, fillinfv]\n",
    "#     fillinstrat = np.where(np.isnan(strat[i, :]))\n",
    "\n",
    "###—————————————————————— Find area of cross section\n",
    "# fig = plt.figure()\n",
    "# xs_area = plt.fill_between(np.arange(0, xy_topo.shape[1]), xy_topo[0, :], xy_topo[-1, :])\n",
    "# plt.close(fig)\n",
    "# xs_verts = xs_area.get_paths()[0].vertices\n",
    "# xs_polygon = Polygon(xs_verts) \n",
    "# xs_bds = xs_polygon.bounds\n",
    "# xs_area = xs_polygon.area\n",
    "# xsleft = xs_bds[0]\n",
    "# xsbottom = xs_bds[1]\n",
    "# xsright = xs_bds[2]\n",
    "# xstop = xs_bds[3]\n",
    "# xs_thick = abs(np.nanmin(xy_topo[-1])-np.nanmax(xy_topo))\n",
    "# xs_width = xsright-xsleft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "2761ce58-ff22-4bce-8a20-28b60497270f",
   "metadata": {},
   "outputs": [],
   "source": [
    "abc = allbars[allbars['iloc']==iloc].index ## get indi ces of ilocs that correspond to this iloc\n",
    "\n",
    "for i in abc:\n",
    "    arrnm = allbars['array name'].iloc[i]\n",
    "    start = allbars['StartTime'].iloc[i]\n",
    "    end = allbars['EndTime'].iloc[i]+1\n",
    "    left = allbars['LeftEdge'].iloc[i]\n",
    "    right = allbars['RightEdge'].iloc[i]+1\n",
    "    \n",
    "    xy_stratc = strat[start:end, left:right]\n",
    "   \n",
    "    if not os.path.exists(f'/Volumes/SAF_Data/NAYS2DH_files/Data/nparrays/barpkg-arrays/{tpo_savefol}/{iloc}'):\n",
    "        os.makedirs(f'/Volumes/SAF_Data/NAYS2DH_files/Data/nparrays/barpkg-arrays/{tpo_savefol}/{iloc}')\n",
    "\n",
    "    np.save(f'/Volumes/SAF_Data/NAYS2DH_files/Data/nparrays/barpkg-arrays/{tpo_savefol}/{iloc}/{arrnm}', xy_stratc, allow_pickle=True)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d9db0336-8341-4a66-aa60-e3634efaa1cd",
   "metadata": {},
   "source": [
    "arr = np.load(f'/Volumes/SAF_Data/NAYS2DH_files/Data/nparrays/barpkg-arrays/{tpo_savefol}/{iloc}/{arrnm}.npy', allow_pickle=True)\n",
    "for i in range (0, arr.shape[0]):\n",
    "    plt.plot(arr[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb93baae-49dc-4b5e-89f8-e1987d74aef2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
