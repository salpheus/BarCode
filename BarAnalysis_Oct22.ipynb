{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "738027f7-d03d-41b0-a2e6-24416f21141d",
   "metadata": {},
   "source": [
    "## Main code to analyse preservation trends in bar packages. \n",
    "Inputs = CSVs with bar stats, and various input arrays for package statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dbe949d3-0550-4022-b83c-40e14762dc0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from copy import deepcopy\n",
    "import itertools\n",
    "from matplotlib import cm\n",
    "from pylab import *\n",
    "\n",
    "\n",
    "import os\n",
    "import seaborn as sns\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import scipy.stats as stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "18cf2281-46cc-4024-920e-c31608657d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Set Color maps for plots and plot aesthetics\n",
    "\n",
    "coher_cols = ['#276419', '#9ccf64', '#f7f7f7', '#e896c4', '#8e0152'] ##PiYG 5 steps\n",
    "coher_cols_seq = ['#d8ffff', '#85d9f0', '#2cb0e0', '#0083c6', '#0057a7'] #light blue to blue\n",
    "# pres_cols = ['xkcd:pink', 'xkcd:lavender', 'xkcd:light grey'] #pink = FP, lav = PP, blue = TR\n",
    "pres_cols = ['xkcd:primary blue', 'xkcd:soft blue', 'xkcd:pink red']\n",
    "proc_cols = ['#ff8500', '#ffca20', '#ffffe0', '#bf74e7', '#8044da'] #(orange to purple) agg to lat acc\n",
    "pres_palette = sns.color_palette(pres_cols)\n",
    "coh_palette = sns.color_palette(coher_cols_seq)\n",
    "proc_palette = sns.color_palette(proc_cols)\n",
    "\n",
    "font = {'family' : 'Helvetica',\n",
    "        'weight' : 'normal',\n",
    "        'size'   : 8}\n",
    "\n",
    "mpl.rc('font', **font)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54d70a80-5cd2-402a-84f5-49c84cabe2c0",
   "metadata": {},
   "source": [
    "Import files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "065462b2-3e4d-45fd-b980-f7038168ff2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/yg/89nlrh5x2xzgdlgr2bczm4_m0000gn/T/ipykernel_5872/3141334978.py:18: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  skewness['File'] = skewness['File'].str.replace('.npy', '')\n",
      "/var/folders/yg/89nlrh5x2xzgdlgr2bczm4_m0000gn/T/ipykernel_5872/3141334978.py:22: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  cvs['File'] = cvs['File'].str.replace('.npy', '')\n"
     ]
    }
   ],
   "source": [
    "filenm = 'agubh2-100m'\n",
    "xlsxname = filenm+'.xlsx'\n",
    "savefilesto = '/Volumes/SAF_Data/bar-manuscript_sum22/data-interp/'\n",
    "mypath = f'/Volumes/SAF_Data/NAYS2DH_files/Data/BarCSVs/concat-files/{xlsxname}'\n",
    "allbars = pd.read_excel(mypath, header=0, usecols = 'A:BF') ## change if you add more columns to the raw dataset\n",
    "eqt = 65 ## time for the bed to equilibrate\n",
    "\n",
    "## import all additional datasets\n",
    "## array of number of active channels\n",
    "active_channels = np.load('/Volumes/SAF_Data/NAYS2DH_files/Data/nparrays/agubh2_active_channels-ud.npy') \n",
    "\n",
    "## array of wetted width\n",
    "wetted_width = np.load('/Volumes/SAF_Data/NAYS2DH_files/Data/nparrays/agubh2WWmaster-ud.npy') \n",
    "wetted_width[:eqt, :] = np.nan \n",
    "\n",
    "##csv of skewness values of centroids\n",
    "skewness = pd.read_csv('/Volumes/SAF_Data/NAYS2DH_files/Data/BarCSVs/concat-files/CentroidTrajectories_Skew.csv') \n",
    "skewness['File'] = skewness['File'].str.replace('.npy', '')\n",
    "\n",
    "## array of thickness measurements of packages like Sinead\n",
    "cvs = pd.read_csv(f'/Volumes/SAF_Data/NAYS2DH_files/Data/BarCSVs/concat-files/LysterthicknessCVs.csv') \n",
    "cvs['File'] = cvs['File'].str.replace('.npy', '')\n",
    "\n",
    "for col, dat in cvs.iloc[:, 6:].iteritems():\n",
    "    cvs[col] = cvs[col].str.replace('[', '', regex = False)\n",
    "    cvs[col] = cvs[col].str.replace(']', '', regex = False)\n",
    "    cvs[col] = cvs[col].astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3018a578-2d38-4dcc-9d62-f8800dfb08ce",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Add extra ratios to allbars dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "96339fb1-1562-4229-a95e-8a3713b11302",
   "metadata": {},
   "outputs": [],
   "source": [
    "allbars['CVFlowDepth'] = allbars['SDFlowDepth']/allbars['MeanFlowDepth']\n",
    "allbars['CVVelocity'] = allbars['SDVelocity']/allbars['MeanVelocity']\n",
    "allbars['Skew Abs'] = abs(allbars['Angle Skewness'])\n",
    "\n",
    "\n",
    "# df.loc[ df[“column_name”] == “some_value”, “column_name”] = “value”\n",
    "allbars['TempAgg'] = allbars['MedClinoHt']/allbars['MaxClinoHt']\n",
    "allbars['Skew Binned'] = allbars['Skew Abs']\n",
    "allbars.loc[np.logical_or(allbars['Skew Abs'] > 1, allbars['Skew Abs'] < 3), 'Skew Binned'] = 1\n",
    "allbars.loc[allbars['Skew Abs'] < 1, 'Skew Binned'] = 0\n",
    "allbars.loc[allbars['Skew Abs'] > 3, 'Skew Binned'] = 2\n",
    "\n",
    "allbars['Co Binned'] = allbars['Skew Abs']\n",
    "allbars.loc[np.logical_or(allbars['CoherenceVal'] > 2, allbars['CoherenceVal'] <= 3), 'Co Binned'] = 1\n",
    "allbars.loc[allbars['CoherenceVal'] <= 2, 'Co Binned'] = 0\n",
    "\n",
    "allbars.loc[allbars['CoherenceVal'] > 3, 'Co Binned'] = 2\n",
    "\n",
    "allbars['BSR Binned'] = allbars['Basal Surf Relief']\n",
    "allbars.loc[np.logical_or(allbars['Basal Surf Relief'] > 0.5, allbars['Basal Surf Relief'] < 1), 'BSR Binned'] = 1\n",
    "allbars.loc[allbars['Basal Surf Relief'] < 0.5, 'BSR Binned'] = 0\n",
    "allbars.loc[allbars['Basal Surf Relief'] > 1, 'BSR Binned'] = 2\n",
    "\n",
    "## recalc facies\n",
    "d50 = 0.00031\n",
    "# chezy_rough = 18*(np.log10(4*allbars['MedFlowDepth']/d50)) #i think this is log10, else they would've put ln no?\n",
    "\n",
    "med_mmp =(1000*(allbars['MedVelocity']**2))/(1650*((18*(np.log10(4*allbars['MedFlowDepth']/d50)))**2)*d50)##### modified mobility parameter\n",
    "allbars['MeanFacies'] =(1000*(allbars['MeanVelocity']**2))/(1650*((18*(np.log10(4*allbars['MeanFlowDepth']/d50)))**2)*d50)##### modified mobility parameter\n",
    "allbars['MedFacies'] =(1000*(allbars['MedVelocity']**2))/(1650*((18*(np.log10(4*allbars['MedFlowDepth']/d50)))**2)*d50)##### modified mobility parameter\n",
    "\n",
    "allbars['BinFacMean'] = allbars['MeanFacies']\n",
    "allbars.loc[allbars['MeanFacies'] < 0.17, 'BinFacMean'] = 'LB'\n",
    "allbars.loc[allbars['MeanFacies'] > 0.17, 'BinFacMean'] = 'UB'\n",
    "\n",
    "allbars['BarHeight/MaxFD'] = allbars['BarHeight']/allbars['MaxFlowDepth']\n",
    "allbars['MaxClino/MaxFD'] = allbars['MaxClinoHt']/allbars['MaxFlowDepth']\n",
    "allbars['MaxClino/MedFD'] = allbars['MaxClinoHt']/allbars['MedFlowDepth']\n",
    "allbars['MedClino/MedFD'] = allbars['MedClinoHt']/allbars['MedFlowDepth']\n",
    "\n",
    "allbars['BFscaling'] = allbars['MaxClinoHt']/1.5\n",
    "allbars['BL/CL'] = allbars['BarWidth']/allbars['MaxClinoWt']\n",
    "allbars['ReconFlowDepth'] = allbars['MaxClinoHt']/0.7 ## I think its 0.7 \n",
    "\n",
    "## Find the proportion of upper bar facies in each bar package\n",
    "\n",
    "allbars['UBar'] = np.nan\n",
    "allbars['mmpmean'] = np.nan\n",
    "allbars['FaciesCV'] = np.nan\n",
    "\n",
    "arrayfolder = 'agubh2-100m-mmp'\n",
    "# init = '/Volumes/SAF_Data/NAYS2DH_files/Data/nparrays/barpkg-arrays/Summer-bpkg-redo/JULY142022'\n",
    "init = f'/Volumes/SAF_Data/NAYS2DH_files/Data/nparrays/barpkg-arrays/{arrayfolder}'\n",
    "\n",
    "for root, dirs, files in os.walk(init):\n",
    "    for file in files:\n",
    "        arr = np.load(os.path.join(root, file), allow_pickle = True)\n",
    "        arrnm = file[:-4]\n",
    "        mmp = arr[:, :, -1] ## the arrays already have the mmp values in them\n",
    "        mmpmean = np.nanmean(mmp)\n",
    "        mmpcv = np.nanstd(mmp)/np.nanmean(mmp)\n",
    "\n",
    "        tot = np.count_nonzero(~np.isnan(mmp))\n",
    "        pub = (mmp <= 0.15).sum()/tot\n",
    "        plb = (mmp > 0.15).sum()/tot\n",
    "        allbars.loc[allbars['array name']==arrnm, 'UBar'] = pub*100\n",
    "        allbars.loc[allbars['array name']==arrnm, 'mmpmean'] = mmpmean\n",
    "        allbars.loc[allbars['array name']==arrnm, 'FaciesCV'] = mmpcv\n",
    "\n",
    "allbars = pd.merge(allbars, skewness, left_on = 'array name', right_on = 'File')\n",
    "allbars = pd.merge(allbars, cvs, left_on = 'array name', right_on = 'File')\n",
    "\n",
    "allbars['CVClinoWt'] = allbars['SDClinoWt']/allbars['MeanClinoWt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4ec98ee3-4182-4136-9498-b3327cab18e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['BarName', 'array name', 'iloc', 'PreservChar', 'PresNum',\n",
       "       'CoherenceVal', 'StartTime', 'EndTime', 'ElapsedTime', 'LeftEdge',\n",
       "       'RightEdge', 'BarWidth', 'BarHeight', 'BarAspect', 'BarArea',\n",
       "       'Section Area', 'ChannelProp', 'Angle Skewness', 'Basal Surf Relief',\n",
       "       'Mean dzdx', 'Median dzdx', 'MinClinoHt', 'MaxClinoHt', 'ModeClinoHt',\n",
       "       'MeanClinoHt', 'SDClinoHt', 'MedClinoHt', 'MinClinoWt', 'MaxClinoWt',\n",
       "       'ModeClinoWt', 'MeanClinoWt', 'SDClinoWt', 'MedClinoWt', 'MinClinoICD',\n",
       "       'MaxClinoICD', 'ModeClinoICD', 'MeanClinoICD', 'SDClinoICD',\n",
       "       'MedClinoICD', 'MinFlowDepth', 'MaxFlowDepth', 'ModeFlowDepth',\n",
       "       'MeanFlowDepth', 'SDFlowDepth', 'MedFlowDepth', 'MinShear', 'MaxShear',\n",
       "       'ModeShear', 'MeanShear', 'SDShear', 'MedShear', 'MinVelocity',\n",
       "       'MaxVelocity', 'ModeVelocity', 'MeanVelocity', 'SDVelocity',\n",
       "       'MedVelocity', 'process interp', 'CVFlowDepth', 'CVVelocity',\n",
       "       'Skew Abs', 'TempAgg', 'Skew Binned', 'Co Binned', 'BSR Binned',\n",
       "       'MeanFacies', 'MedFacies', 'BinFacMean', 'BarHeight/MaxFD',\n",
       "       'MaxClino/MaxFD', 'MaxClino/MedFD', 'MedClino/MedFD', 'BFscaling',\n",
       "       'BL/CL', 'ReconFlowDepth', 'UBar', 'mmpmean', 'FaciesCV',\n",
       "       'Unnamed: 0_x', 'File_x', 'Skewness', 'Unnamed: 0_y', 'File_y', '1mCV',\n",
       "       '1mcount', '1mmean', '1msd', '2mCV', '2mcount', '2mmean', '2msd',\n",
       "       '5mCV', '5mcounts', '5mmean', '5msd', '10mCV', '10mcounts', '10mmean',\n",
       "       '10msd', 'CVClinoWt'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allbars.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20300980-9bf8-4b47-88de-7253a62473fe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
